{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc6b4ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "from ipynb.fs.full.Preprocessing import preprocess\n",
    "from collections import Counter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "821153c1",
   "metadata": {},
   "source": [
    "# Decision Tree Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "588e29e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, train_y, test_x, test_y = preprocess(100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b034a627",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This one uses Counter\n",
    "class Node:\n",
    "    #The tree is defined with nodes that have nodes in them. The process will be implemented recursively \n",
    "    #in later parts.\n",
    "    \n",
    "    def __init__(self, depth=None,right_node=None, left_node=None,node_type=None,node_class = None,split_feature = None,split_threshold = None ):\n",
    "        #The building block of the tree.\n",
    "        #The tree is a node that have nodes...\n",
    "        self.left_node = left_node\n",
    "        self.right_node =right_node\n",
    "        self.node_type = node_type\n",
    "        self.node_class = node_class\n",
    "        self.split_feature = split_feature\n",
    "        self.split_threshold = split_threshold\n",
    "\n",
    "class DecisionTree:\n",
    "    def __init__(self, data=None, labels=None,max_split =500,min_member=5):\n",
    "        self.max_split=max_split\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        self.min_member=min_member\n",
    "        \n",
    "    def get_class(self,labels):\n",
    "        unique, counts = np.unique(labels, return_counts=True)\n",
    "        counter = dict(zip(unique, counts))\n",
    "        return max(labels, key=lambda x: counter[x])\n",
    "\n",
    "    def run(self,data,labels,split_number):\n",
    "\n",
    "        #This is the function where the recursion happens: nodes that have nodes.\n",
    "       \n",
    "        split_feature,split_threshold,gini = self.get_splitting_point(data,labels) #returns the feature index and the threshold\n",
    "        if gini > 0 and split_number< self.max_split and len(labels) > self.min_member: #split until spliting conditions are met\n",
    "            right_data, left_data,right_labels,left_labels = self.get_split(split_feature, split_threshold, data,labels)\n",
    "            right_node = self.run(data=right_data,labels = right_labels,split_number=split_number+1) \n",
    "            left_node = self.run(data = left_data,labels=left_labels,split_number=split_number+1)\n",
    "            return Node(node_type = \"branch\",right_node = right_node, left_node = left_node,split_feature=split_feature,split_threshold=split_threshold,depth=split_number  )\n",
    "        else:\n",
    "            return Node(node_type = \"leaf\",node_class = self.get_class(labels))\n",
    "    def get_splitting_point(self,data,labels):\n",
    "        num_instances, num_features = np.shape(data)\n",
    "        gini =np.inf\n",
    "        for feature in range(num_features):\n",
    "            split_threshold, gini_gain = self.best_of_feature_split(data,labels,feature)\n",
    "            if gini_gain<gini:\n",
    "                gini = gini_gain\n",
    "                best_split_threshold , best_split_feature = split_threshold,feature\n",
    "        return best_split_feature,best_split_threshold,gini \n",
    "        #return split_feature, split_threshold, gini_gain\n",
    "    def best_of_feature_split(self,data,labels,split_feature):\n",
    "        feature_col = data[:,split_feature]\n",
    "        thresholds = np.unique(feature_col, return_counts=False) #using the values as thresholds to make it efficient\n",
    "        min_gini = np.inf \n",
    "        for threshold in thresholds:\n",
    "            right_data, left_data,right_labels,left_labels = self.get_split(split_feature,threshold,data,labels)\n",
    "            len_right = len(right_labels)\n",
    "            len_left = len(left_labels)\n",
    "            gini = self.gini_index(right_labels)*(len_right/(len_right+len_left))+self.gini_index(left_labels)*(len_left/(len_right+len_left))\n",
    "            if gini < min_gini:\n",
    "                min_gini = gini\n",
    "                split_threshold = threshold\n",
    "        return split_threshold, min_gini\n",
    "    def get_split(self,split_feature,split_threshold,data,labels):\n",
    "        feature_col = data[:,split_feature]\n",
    "        pos1 =np.where(feature_col>split_threshold)[0]\n",
    "        pos2 = np.where(feature_col<=split_threshold)[0]\n",
    "        right_data = data[pos1]\n",
    "        left_data=data[pos2]\n",
    "        left_labels=labels[pos2] \n",
    "        right_labels=labels[pos1]  \n",
    "        return right_data, left_data,right_labels,left_labels   \n",
    "    def fit(self):\n",
    "        self.decision_maker = self.run(self.data,self.labels,0) #this returns a node instance \n",
    "    def predict(self,new_data):\n",
    "        predictions = list()\n",
    "        for row in new_data:\n",
    "            predictions.append(self.infer(self.decision_maker,row))\n",
    "        return predictions\n",
    "            \n",
    "    def infer(self,node,datapoint):\n",
    "        if node.node_type == \"branch\":\n",
    "            val = datapoint[node.split_feature] \n",
    "            if val > node.split_threshold:\n",
    "                return self.infer(node.right_node,datapoint)\n",
    "            else:\n",
    "                return self.infer(node.left_node,datapoint)\n",
    "        elif node.node_type == \"leaf\":\n",
    "                return node.node_class\n",
    "    def gini_index(self,labels):\n",
    "        length = len(labels)\n",
    "\n",
    "        counter = Counter(labels)\n",
    "        gini = 1\n",
    "        for val in counter.values():\n",
    "            gini -= (val/length)**2\n",
    "        return gini\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f3607b",
   "metadata": {},
   "source": [
    "**Training and Inference Time**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "97219ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Tree = DecisionTree(train_x[:1000],train_y[:1000],max_split =100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "37e52cbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.439424991607666\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "t1 = time()\n",
    "Tree.fit()\n",
    "print(time()-t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cb324e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = Tree.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "891eec70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95.00999999999999\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for ind,prediction in enumerate(predictions):\n",
    "    if test_y[ind]==prediction:\n",
    "        count+=1\n",
    "print((count/len(predictions))*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e4bbfd",
   "metadata": {},
   "source": [
    "**Evaluation Metrics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "802eea8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrice(pred,truth,num_of_class):\n",
    "    \"\"\"\n",
    "    Return the confusion matrix where the column indexes are predictions and \n",
    "    row indexes are ground truths.\n",
    "    \n",
    "    \"\"\"\n",
    "    confusion_mtrx=np.zeros((num_of_class,num_of_class),dtype=np.int32)\n",
    "    for ind,prediction in enumerate(predictions):\n",
    "        confusion_mtrx[truth[ind]][prediction]+=1\n",
    "    \n",
    "    dataframe = pd.DataFrame(data=confusion_mtrx,   index=np.arange(0,num_of_class),   columns=np.arange(0,num_of_class))\n",
    "    dataframe = dataframe.style.set_caption('The Confusion Matrix ')\n",
    "    return dataframe\n",
    "def accuracy(pred,truth):\n",
    "    count = 0\n",
    "\n",
    "    for ind,prediction in enumerate(predictions):\n",
    "        if truth[ind]==prediction:\n",
    "            count+=1\n",
    "    accuracy = (count/len(predictions))*100\n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4ad2b8e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95.00999999999999\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "</style><table id=\"T_e6cb7_\" ><caption>The Confusion Matrix </caption><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >0</th>        <th class=\"col_heading level0 col1\" >1</th>        <th class=\"col_heading level0 col2\" >2</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_e6cb7_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "                        <td id=\"T_e6cb7_row0_col0\" class=\"data row0 col0\" >11495</td>\n",
       "                        <td id=\"T_e6cb7_row0_col1\" class=\"data row0 col1\" >286</td>\n",
       "                        <td id=\"T_e6cb7_row0_col2\" class=\"data row0 col2\" >78</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_e6cb7_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "                        <td id=\"T_e6cb7_row1_col0\" class=\"data row1 col0\" >545</td>\n",
       "                        <td id=\"T_e6cb7_row1_col1\" class=\"data row1 col1\" >3201</td>\n",
       "                        <td id=\"T_e6cb7_row1_col2\" class=\"data row1 col2\" >1</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_e6cb7_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "                        <td id=\"T_e6cb7_row2_col0\" class=\"data row2 col0\" >87</td>\n",
       "                        <td id=\"T_e6cb7_row2_col1\" class=\"data row2 col1\" >1</td>\n",
       "                        <td id=\"T_e6cb7_row2_col2\" class=\"data row2 col2\" >4306</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x293f4838160>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(accuracy(predictions, test_y))\n",
    "confusion_matrice(predictions, test_y,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e84c9bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sn\n",
    "\n",
    "def confusion_matrix(test_x, test_y, weights, bias):\n",
    "    prediction = make_prediction(test_x, weights, bias)    \n",
    "    confusion_matrix = np.zeros((3, 3), dtype=int)\n",
    "    \n",
    "    accurate_prediction_count = 0\n",
    "    for i, pred in enumerate(prediction):\n",
    "        if test_y[i][0] == 0:\n",
    "            if pred == 0: \n",
    "                confusion_matrix[0][0] += 1\n",
    "            elif pred == 1:\n",
    "                confusion_matrix[0][1] += 1\n",
    "            elif pred == 2:\n",
    "                confusion_matrix[0][2] += 1\n",
    "        \n",
    "        elif test_y[i][0] == 1:\n",
    "            if pred == 0:\n",
    "                confusion_matrix[1][0] += 1\n",
    "            elif pred == 1:\n",
    "                confusion_matrix[1][1] += 1\n",
    "            elif pred == 2:\n",
    "                confusion_matrix[1][2] += 1\n",
    "                \n",
    "        elif test_y[i][0] == 2:\n",
    "            if pred == 0:\n",
    "                confusion_matrix[2][0] += 1\n",
    "            elif pred == 1:\n",
    "                confusion_matrix[2][1] += 1\n",
    "            elif pred == 2:\n",
    "                confusion_matrix[2][2] += 1\n",
    "        \n",
    "        if pred == test_y[i][0]:\n",
    "            accurate_prediction_count += 1\n",
    "            \n",
    "    \n",
    "    s = sn.heatmap(confusion_matrix, annot=True, fmt='g')\n",
    "    s.set(xlabel='Predicted Labels', ylabel='True Labels')\n",
    "    plt.show()\n",
    "    return accurate_prediction_count / test_y.shape[0] * 100 \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5665dc82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b5f7ef3e",
   "metadata": {},
   "source": [
    " **Performance Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "id": "cde45237",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timer unit: 1e-07 s\n",
      "\n",
      "Total time: 10.2305 s\n",
      "File: C:\\Users\\Onat\\AppData\\Local\\Temp/ipykernel_18724/1133872911.py\n",
      "Function: build_the_tree at line 21\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "    21                                               def build_the_tree(self,data,labels,current_depth):\n",
      "    22        53        277.0      5.2      0.0          try:\n",
      "    23        53       3304.0     62.3      0.0              num_instances, num_features = np.shape(data)\n",
      "    24                                                   except ValueError:\n",
      "    25                                                       return Node(node_type = \"leaf\",node_class = None)\n",
      "    26        53  102260790.0 1929448.9    100.0          split_feature,split_threshold,gini = self.get_splitting_point(data,labels) #returns the feature index and the threshold\n",
      "    27                                                   \n",
      "    28        53        742.0     14.0      0.0          if gini > 0 and current_depth< self.max_depth and len(labels) > self.min_member:\n",
      "    29        26      11402.0    438.5      0.0              right_data, left_data,right_labels,left_labels = self.get_split(split_feature, split_threshold, data,labels)\n",
      "    30        26        638.0     24.5      0.0              right_node = self.build_the_tree(data=right_data,labels = right_labels,current_depth=current_depth+1)\n",
      "    31        26        413.0     15.9      0.0              left_node = self.build_the_tree(data = left_data,labels=left_labels,current_depth=current_depth+1)\n",
      "    32        26        917.0     35.3      0.0              return Node(node_type = \"branch\",right_node = right_node, left_node = left_node,split_feature=split_feature,split_threshold=split_threshold,depth=current_depth  )\n",
      "    33        27      26537.0    982.9      0.0          return Node(node_type = \"leaf\",node_class = self.get_class(labels))\n",
      "\n",
      "Total time: 10.225 s\n",
      "File: C:\\Users\\Onat\\AppData\\Local\\Temp/ipykernel_18724/1133872911.py\n",
      "Function: get_splitting_point at line 34\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "    34                                               def get_splitting_point(self,data,labels):\n",
      "    35        53       1373.0     25.9      0.0          num_instances, num_features = np.shape(data)\n",
      "    36        53        359.0      6.8      0.0          gini =np.inf\n",
      "    37       689       3865.0      5.6      0.0          for feature in range(num_features):\n",
      "    38       636  102239891.0 160754.5    100.0              split_threshold, gini_gain = self.best_of_feature_split(data,labels,feature)\n",
      "    39       636       3081.0      4.8      0.0              if gini_gain<gini:\n",
      "    40       120        456.0      3.8      0.0                  gini = gini_gain\n",
      "    41       120        605.0      5.0      0.0                  best_split_threshold , best_split_feature = split_threshold,feature\n",
      "    42        53        224.0      4.2      0.0          return best_split_feature,best_split_threshold,gini \n",
      "    43                                                   #return split_feature, split_threshold, gini_gain\n",
      "\n",
      "Total time: 10.0261 s\n",
      "File: C:\\Users\\Onat\\AppData\\Local\\Temp/ipykernel_18724/1133872911.py\n",
      "Function: best_of_feature_split at line 44\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "    44                                               def best_of_feature_split(self,data,labels,split_feature):\n",
      "    45       636       7491.0     11.8      0.0          feature_col = data[:,split_feature]\n",
      "    46                                                   \n",
      "    47       636     400552.0    629.8      0.4          thresholds = np.unique(feature_col, return_counts=False) #using the values as thresholds to make it efficient\n",
      "    48                                                   \n",
      "    49       636       6255.0      9.8      0.0          min_gini = np.inf \n",
      "    50     79615     389684.0      4.9      0.4          for threshold in thresholds:\n",
      "    51     78979   58868883.0    745.4     58.7              right_data, left_data,right_labels,left_labels = self.get_split(split_feature,threshold,data,labels)\n",
      "    52     78979     569774.0      7.2      0.6              len_right = len(right_labels)\n",
      "    53     78979     403733.0      5.1      0.4              len_left = len(left_labels)\n",
      "    54     78979   39097273.0    495.0     39.0              gini = self.gini_index(right_labels)*(len_right/(len_right+len_left))+self.gini_index(left_labels)*(len_left/(len_right+len_left))\n",
      "    55     78979     386150.0      4.9      0.4              if gini < min_gini:\n",
      "    56     14995      63981.0      4.3      0.1                  min_gini = gini\n",
      "    57     14995      64520.0      4.3      0.1                  split_threshold = threshold\n",
      "    58       636       3108.0      4.9      0.0          return split_threshold, min_gini\n",
      "\n",
      "Total time: 3.30149 s\n",
      "File: C:\\Users\\Onat\\AppData\\Local\\Temp/ipykernel_18724/1133872911.py\n",
      "Function: gini_index at line 65\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "    65                                               def gini_index(self,labels):\n",
      "    66    157958     759554.0      4.8      2.3          length = len(labels)\n",
      "    67                                           \n",
      "    68    157958   26541060.0    168.0     80.4          counter = Counter(labels)\n",
      "    69    157958     700151.0      4.4      2.1          gini = 1\n",
      "    70    448720    2157778.0      4.8      6.5          for val in counter.values():\n",
      "    71    290762    2346211.0      8.1      7.1              gini -= (val/length)**2\n",
      "    72    157958     510193.0      3.2      1.5          return gini\n",
      "\n",
      "Total time: 4.67587 s\n",
      "File: C:\\Users\\Onat\\AppData\\Local\\Temp/ipykernel_18724/1133872911.py\n",
      "Function: get_split at line 73\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "    73                                               def get_split(self,split_feature,split_threshold,data,labels):\n",
      "    74                                               \n",
      "    75     79005     878278.0     11.1      1.9          feature_col = data[:,split_feature]\n",
      "    76                                           \n",
      "    77     79005   12340922.0    156.2     26.4          pos1 =np.where(feature_col>split_threshold)[0]\n",
      "    78     79005   10586384.0    134.0     22.6          pos2 = np.where(feature_col<=split_threshold)[0]\n",
      "    79     79005   10091618.0    127.7     21.6          right_data = data[pos1]\n",
      "    80     79005    9481958.0    120.0     20.3          left_data=data[pos2]\n",
      "    81     79005    1629760.0     20.6      3.5          left_labels=labels[pos2] \n",
      "    82     79005    1374758.0     17.4      2.9          right_labels=labels[pos1]  \n",
      "    83     79005     375039.0      4.7      0.8          return right_data, left_data,right_labels,left_labels   \n",
      "\n",
      "Total time: 10.231 s\n",
      "File: C:\\Users\\Onat\\AppData\\Local\\Temp/ipykernel_18724/1133872911.py\n",
      "Function: fit at line 84\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "    84                                               def fit(self):\n",
      "    85         1  102310350.0 102310350.0    100.0          self.decision_maker = self.build_the_tree(self.data,self.labels,0) #this returns a node instance \n",
      "\n"
     ]
    }
   ],
   "source": [
    "Tree = DecisionTree(train_x[:1000],train_y[:1000])\n",
    "from line_profiler import LineProfiler\n",
    "lp = LineProfiler()\n",
    "lp.enable_by_count()\n",
    "lp.add_function(Tree.best_of_feature_split)\n",
    "lp.add_function(Tree.get_split)\n",
    "lp.add_function(Tree.get_splitting_point)\n",
    "lp.add_function(Tree.run)\n",
    "lp.add_function(Tree.gini_index)\n",
    "lp_wrapper = lp(Tree.fit)\n",
    "Tree.fit()\n",
    "lp.print_stats()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "51db195162f82df05c60f2be968350518dfdf1445cc2d24d16ac47e24cb84d87"
  },
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
